knit_with_parameters('~/Desktop/Untitled.Rmd')
##load necessary libraries
library(lme4)
library(lmerTest)
library(effects)
library(car)
library(tidyverse)
library(lattice)
library(ordinal)
library(ggeffects)
library(brms)
library(magrittr)
##First look at the data
prod <- prod
str(prod)
prod_data <- prod %>%
##reorder the levels of factors for analysis
mutate(
argument = factor(argument,
levels = c("3", "2", "1")),
statement = factor(statement,
levels = c("1", "2", "3", "4"))
) %>%
##rename the variables
mutate(
argument = recode(argument,
"3" = "No",
"2" = "Some",
"1" = "Everyone"),
statement = recode(statement,
"1" = "Strong.Agree",
"2" = "Somewhat.Agree",
"3" = "Somewhat.Disagree",
"4" = "Strong.Disagree")
)
##check the results
str(prod_data)
levels(prod_data$argument)
##leave only the complete cases
prod_data <- prod_data[complete.cases(prod_data),]
prod_tsk <- prod_data %>%
##subset the data to only include the critical items, no fillers
subset(
item.type == "critical"
) %<>%
##converting variables to factors
mutate_at(
c("item.type","strength", "agreement"), funs(factor(.))
)
str(prod_tsk)
##create the counts for each argument choosen
prod_count <- prod_tsk %>%
##count data
count(argument
) %>%
##percentage data using the n which is taken from count argument
mutate(
pctg = ((n/sum(n))*100)
)
##plot of counts
ggplot(prod_count, aes(x = argument, y = n)) +
geom_bar(stat = "identity", aes(fill = argument))  +
coord_cartesian(ylim = c(0, 1900)) +
ylab("Count of total replies") +
xlab("Quantifier chosen") +
ggtitle("Count of arguments chosen") +
theme_bw()
##plot of percentages
ggplot(prod_count, aes(x = argument, y = pctg)) +
geom_bar(stat = "identity", aes(fill = argument))  +
coord_cartesian(ylim = c(0, 100)) +
ylab("% of total replies") +
xlab("Quantifier") +
labs(fill = "Quantifier") +
theme_bw()
##table for the chi square analysis
M <- as.table(cbind(c(1669, 897, 330)))
dimnames(M) <- list(quantifier = c("No", "Some", "Everyone"),
responses = c("count"))
##chi square test and summary
chi.counts <- chisq.test(M)
chi.counts
chi.counts$observed   # observed counts (same as M)
chi.counts$expected   # expected counts under the null
chi.counts$residuals  # Pearson residuals
chi.counts$stdres     # standardized residuals
unlink('Desktop/Untitled_cache', recursive = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
##load necessary libraries
library(lme4)
library(lmerTest)
library(effects)
library(car)
library(tidyverse)
library(lattice)
library(ordinal)
library(ggeffects)
library(brms)
library(magrittr)
##First look at the data
prod <- prod
str(prod)
prod_data <- prod %>%
##reorder the levels of factors for analysis
mutate(
argument = factor(argument,
levels = c("3", "2", "1")),
statement = factor(statement,
levels = c("1", "2", "3", "4"))
) %>%
##rename the variables
mutate(
argument = recode(argument,
"3" = "No",
"2" = "Some",
"1" = "Everyone"),
statement = recode(statement,
"1" = "Strong.Agree",
"2" = "Somewhat.Agree",
"3" = "Somewhat.Disagree",
"4" = "Strong.Disagree")
)
##check the results
str(prod_data)
levels(prod_data$argument)
##leave only the complete cases
prod_data <- prod_data[complete.cases(prod_data),]
prod_tsk <- prod_data %>%
##subset the data to only include the critical items, no fillers
subset(
item.type == "critical"
) %<>%
##converting variables to factors
mutate_at(
c("item.type","strength", "agreement"), funs(factor(.))
)
str(prod_tsk)
##create the counts for each argument choosen
prod_count <- prod_tsk %>%
##count data
count(argument
) %>%
##percentage data using the n which is taken from count argument
mutate(
pctg = ((n/sum(n))*100)
)
##plot of counts
ggplot(prod_count, aes(x = argument, y = n)) +
geom_bar(stat = "identity", aes(fill = argument))  +
coord_cartesian(ylim = c(0, 1900)) +
ylab("Count of total replies") +
xlab("Quantifier chosen") +
ggtitle("Count of arguments chosen") +
theme_bw()
##plot of percentages
ggplot(prod_count, aes(x = argument, y = pctg)) +
geom_bar(stat = "identity", aes(fill = argument))  +
coord_cartesian(ylim = c(0, 100)) +
ylab("% of total replies") +
xlab("Quantifier") +
labs(fill = "Quantifier") +
theme_bw()
##table for the chi square analysis
M <- as.table(cbind(c(1669, 897, 330)))
dimnames(M) <- list(quantifier = c("No", "Some", "Everyone"),
responses = c("count"))
##chi square test and summary
chi.counts <- chisq.test(M)
chi.counts
chi.counts$observed   # observed counts (same as M)
chi.counts$expected   # expected counts under the null
chi.counts$residuals  # Pearson residuals
chi.counts$stdres     # standardized residuals
knitr::opts_chunk$set(echo = TRUE)
prod_data <- prod %>%
##reorder the levels of factors for analysis
mutate(
argument = factor(argument,
levels = c("3", "2", "1")),
statement = factor(statement,
levels = c("1", "2", "3", "4"))
) %>%
##rename the variables
mutate(
argument = recode(argument,
"3" = "No",
"2" = "Some",
"1" = "Everyone"),
statement = recode(statement,
"1" = "Strong.Agree",
"2" = "Somewhat.Agree",
"3" = "Somewhat.Disagree",
"4" = "Strong.Disagree")
)
prod_data <- prod %>%
##reorder the levels of factors for analysis
mutate(
argument = factor(argument,
levels = c("3", "2", "1")),
statement = factor(statement,
levels = c("1", "2", "3", "4"))
) %>%
##rename the variables
mutate(
argument = recode(argument,
"3" = "No",
"2" = "Some",
"1" = "Everyone"),
statement = recode(statement,
"1" = "Strong.Agree",
"2" = "Somewhat.Agree",
"3" = "Somewhat.Disagree",
"4" = "Strong.Disagree")
)
prod_data <- prod %>%
##reorder the levels of factors for analysis
mutate(
argument = factor(argument,
levels = c("3", "2", "1")),
statement = factor(statement,
levels = c("1", "2", "3", "4"))
) %>%
##rename the variables
mutate(statement = recode(statement,
"1" = "Strong.Agree",
"2" = "Somewhat.Agree",
"3" = "Somewhat.Disagree",
"4" = "Strong.Disagree")
)
library("car")
library("lattice")
library("RePsychLing")
library("ggplot2")
library("lme4")
library("dplyr")
library("lmerTest")
library("ggeffects")
library("effects")
library("ordinal")
library("brms")
library("tidyverse")
load("~/Google Drive/R environment 1.RData")
library(lme4)
library(lmerTest)
library(effects)
library(car)
library(tidyverse)
library(lattice)
library(ordinal)
library(ggeffects)
library(brms)
setwd("~/Documents/GitHub/Ad-Pop-Experiment/data")
knitr::opts_chunk$set(echo = TRUE)
##First look at the data
prod <- read.csv("Anchoring_task.csv")
getwd()
##First look at the data
prod <- read.csv("Anchoring_task.csv")
##First look at the data
prod <- read.csv("Anchoring_task.csv")
##First look at the data
prod <- read.csv(file.choose())
str(prod)
head(prod)
setwd("~/Documents/GitHub/Ad-Pop-Experiment")
##First look at the data
prod <- read.csv("data/Anchoring_task.csv")
str(prod)
head(prod)
1/(1+exp(-0)
)
1/(1+exp(-.5))
1/(1+exp(-1))
knitr::opts_chunk$set(echo = TRUE)
##First look at the data
prod <- read.csv("data/Anchoring_task.csv")
str(prod)
head(prod)
##load necessary libraries
library(brms)
library(magrittr)
library(tidyverse)
##Change the factor levels to set dummy coding with No as base level
anchoring$quantifier <- factor(anchoring$quantifier,
levels = c("No", "Some", "Everyone"))
##function to calculate confidence intervals with a gaussian normal distribution
ci <- function(x,y) {
qnorm(0.975)*sd(x)/sqrt(length(unique(y)))
}
##summary of data
anchoring_sum <- anchoring %>%
##grouping element by quantifier
group_by(
quantifier
) %>%
##calculating mean sd and ci for each quantifier
summarise(
count = n(),
mean = mean(value, na.rm = TRUE),
sd = sd(value, na.rm = TRUE),
ci = ci(value, id)
)
##plot of summary
anchoring_plot <- ggplot(anchoring_sum, aes(x=quantifier, y=mean)) +
geom_bar(stat = "identity", aes(fill = quantifier)) +
coord_cartesian(ylim = c(30,90)) + scale_y_continuous(breaks=seq(30, 90, by = 10)) +
geom_errorbar(aes(ymin= mean - ci, ymax = mean + ci), colour = "black", width = 0.2) +
labs(fill = "Quantifier") +
ylab("Quantifier") +
ggtitle("Average values per Quantifier") +
theme_bw() +
theme(legend.position = "none")
##plot of histograms faceted by quantifier levels
h_plot <- ggplot(anchoring) +
geom_histogram(aes(x=value, fill = quantifier), bins = 8) +
geom_vline(xintercept = 50, size = .5, colour = "black",
linetype = "dashed") +
scale_x_continuous(breaks = seq(0, 100, 25)) +
labs(fill = "Quantifier") +
ggtitle("Histogram of replies per Quantifier") +
theme_bw() +
theme(legend.position = "none")+
facet_wrap(~quantifier)
##combination of both plots
gridExtra::grid.arrange(anchoring_plot,h_plot, nrow = 2)
fit2n_l <- loo(fit2n)
fit2z_l <- loo(fit2z)
fit2y_l<- loo(fit2y)
knitr("Experiment_2_workflow")
rmarkdown::render("Experiment_2_workflow.Rmd")
rmarkdown::render("Experiment_2_workflow.Rmd")
##function to calculate confidence intervals with a gaussian normal distribution
ci <- function(x,y) {
qnorm(0.975)*sd(x)/sqrt(length(unique(y)))
}
##summary of data
anchoring_sum <- anchoring %>%
##grouping element by quantifier
group_by(
quantifier
) %>%
##calculating mean sd and ci for each quantifier
summarise(
count = n(),
mean = mean(value, na.rm = TRUE),
sd = sd(value, na.rm = TRUE),
ci = ci(value, id)
)Â¨
##function to calculate confidence intervals with a gaussian normal distribution
ci <- function(x,y) {
qnorm(0.975)*sd(x)/sqrt(length(unique(y)))
}
##summary of data
anchoring_sum <- anchoring %>%
##grouping element by quantifier
group_by(
quantifier
) %>%
##calculating mean sd and ci for each quantifier
summarise(
count = n(),
mean = mean(value, na.rm = TRUE),
sd = sd(value, na.rm = TRUE),
ci = ci(value, id)
)
anchoring_sum
##plot of summary
anchoring_plot <- ggplot(anchoring_sum, aes(x=quantifier, y=mean)) +
geom_bar(stat = "identity", aes(fill = quantifier)) +
coord_cartesian(ylim = c(30,90)) + scale_y_continuous(breaks=seq(30, 90, by = 10)) +
geom_errorbar(aes(ymin= mean - ci, ymax = mean + ci), colour = "black", width = 0.2) +
labs(fill = "Quantifier") +
ylab("Quantifier") +
ggtitle("Average values per Quantifier") +
theme_bw() +
theme(legend.position = "none")
##plot of histograms faceted by quantifier levels
h_plot <- ggplot(anchoring) +
geom_histogram(aes(x=value, fill = quantifier), bins = 8) +
geom_vline(xintercept = 50, size = .5, colour = "black",
linetype = "dashed") +
scale_x_continuous(breaks = seq(0, 100, 25)) +
labs(fill = "Quantifier") +
ggtitle("Histogram of replies per Quantifier") +
theme_bw() +
theme(legend.position = "none")+
facet_wrap(~quantifier)
##combination of both plots
gridExtra::grid.arrange(anchoring_plot,h_plot, nrow = 2)
##plot of summary
anchoring_plot <- ggplot(anchoring_sum, aes(x=quantifier, y=mean)) +
geom_bar(stat = "identity", aes(fill = quantifier)) +
coord_cartesian(ylim = c(30,90)) + scale_y_continuous(breaks=seq(30, 90, by = 10)) +
geom_errorbar(aes(ymin= mean - ci, ymax = mean + ci), colour = "black", width = 0.2) +
labs(fill = "Quantifier") +
ylab("Quantifier") +
ggtitle("Average values per Quantifier") +
theme_bw() +
theme(legend.position = "none")
##plot of histograms faceted by quantifier levels
h_plot <- ggplot(anchoring) +
geom_histogram(aes(x=value, fill = quantifier), bins = 8) +
geom_vline(xintercept = 50, size = .5, colour = "black",
linetype = "dashed") +
scale_x_continuous(breaks = seq(0, 100, 25)) +
labs(fill = "Quantifier") +
ggtitle("Histogram of replies per Quantifier") +
theme_bw() +
theme(legend.position = "none")+
facet_wrap(~quantifier)
##combination of both plots
gridExtra::grid.arrange(anchoring_plot,h_plot, nrow = 2)
##plot of summary
anchoring_plot <- ggplot(anchoring_sum, aes(x=quantifier, y=mean)) +
geom_bar(stat = "identity", aes(fill = quantifier)) +
coord_cartesian(ylim = c(30,90)) + scale_y_continuous(breaks=seq(30, 90, by = 10)) +
geom_errorbar(aes(ymin= mean - ci, ymax = mean + ci), colour = "black", width = 0.2) +
labs(fill = "Quantifier") +
ylab("Quantifier") +
ggtitle("Average values per Quantifier") +
theme_bw() +
theme(legend.position = "none")
##plot of histograms faceted by quantifier levels
h_plot <- ggplot(anchoring) +
geom_histogram(aes(x=value, fill = quantifier), bins = 8) +
geom_vline(xintercept = 50, size = .5, colour = "black",
linetype = "dashed") +
scale_x_continuous(breaks = seq(0, 100, 25)) +
labs(fill = "Quantifier") +
ggtitle("Histogram of replies per Quantifier") +
theme_bw() +
theme(legend.position = "none")+
facet_wrap(~quantifier)
##combination of both plots
gridExtra::grid.arrange(anchoring_plot,h_plot, nrow = 2)
##simple loo comparions of the two models
loo_compare(fit2z_l,fit2y_l, fit2n_l)
knitr::opts_chunk$set(echo = TRUE)
loo_compare(bm3_l,bm3.2_l,bm3n_l) ## simple loo comparison
loo_compare(bm2_l,bm2.2_l, bm2n_l) ## simple loo comparison
loo_compare(bm4_l,bm4.2_l, bm4n_l) ## simple loo comparison
pp_check(fit2y, nsamples = 50)
pp_check(fit2z, nsamples = 50)
##plot of summary
anchoring_plot <- ggplot(anchoring_sum, aes(x=quantifier, y=mean)) +
geom_bar(stat = "identity", aes(fill = quantifier)) +
coord_cartesian(ylim = c(30,90)) + scale_y_continuous(breaks=seq(30, 90, by = 10)) +
geom_errorbar(aes(ymin= mean - ci, ymax = mean + ci), colour = "black", width = 0.2) +
labs(fill = "Quantifier") +
ylab("Quantifier") +
ggtitle("Average values per Quantifier") +
theme_bw() +
theme(legend.position = "none")
##plot of histograms faceted by quantifier levels
h_plot <- ggplot(anchoring) +
geom_histogram(aes(x=value, fill = quantifier), bins = 8) +
geom_vline(xintercept = 50, size = .5, colour = "black",
linetype = "dashed") +
scale_x_continuous(breaks = seq(0, 100, 25)) +
labs(fill = "Quantifier") +
ggtitle("Histogram of replies per Quantifier") +
theme_bw() +
theme(legend.position = "none")+
facet_wrap(~quantifier)
##combination of both plots
gridExtra::grid.arrange(anchoring_plot,h_plot, nrow = 2)
##BayesFactor test between quantifierEveryone and quantifierNo
hypothesis(fit2y, "1/(1+exp(-(Intercept + quantifierEveryone))) = 1/(1+exp(-(Intercept)))")
fit2y
##Intercept and uncorrelated slope model
fit2y <- brm((value/100) ~ 0 + Intercept + quantifier + (quantifier||id) + (quantifier||item),
family = "zero_one_inflated_beta",
sample_prior = TRUE,
save_all_pars = TRUE,
prior = prior_z,
cores = 2,
data = anchoring)
fit2y_l<- loo(fit2y)
##simple loo comparions of the three models
loo_compare(fit2z_l,fit2y_l, fit2n_l)
##Intercept and uncorrelated slope model
fit2y <- brm((value/100) ~ 0 + Intercept + quantifier + (quantifier||id) + (quantifier||item),
family = "zero_one_inflated_beta",
sample_prior = TRUE,
save_all_pars = TRUE,
prior = prior_z,
iter = 4000,
cores = 2,
data = anchoring)
fit2y_l<- loo(fit2y)
##simple loo comparions of the three models
loo_compare(fit2z_l,fit2y_l, fit2n_l)
rmarkdown::render("your_doc.Rmd")
rmarkdown::render("Experiment_2_workflow.Rmd")
fit2y
hypothesis(bm4, "exp(muSome_strengthsomewhat) = exp(muSome_Intercept)") ## BayesFactor test with Savage-Dickey method for equality of Some across both levels of agreement strength
hypothesis(bm4, "exp(muEveryone_strengthsomewhat) = exp(muEveryone_Intercept)") ## BayesFactor test with Savage-Dickey method for equality of Everyone across both levels of agreement strength
1/0.16
1/0.1
100/0.1
1/3.25
1/1
1/1.5
1/2
bm4
plot(marginal_effects(bm4x, probs = c(.05,.95), plot = F, categorical = TRUE)) [[1]] + theme_bw() +
xlab("Strength of agreement") + ylab("probability of replies") +
labs(colour = "Quantifier", fill = "Quantifier")
rmarkdown::render("Experiment_2_workflow.Rmd")
rmarkdown::render("Experiment_1_workflow.Rmd")
save.image("~/Google Drive/R environment 1.RData")
